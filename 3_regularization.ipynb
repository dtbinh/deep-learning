{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kR-4eNdK6lYS"
   },
   "source": [
    "Deep Learning\n",
    "=============\n",
    "\n",
    "Assignment 3\n",
    "------------\n",
    "\n",
    "Previously in `2_fullyconnected.ipynb`, you trained a logistic regression and a neural network model.\n",
    "\n",
    "The goal of this assignment is to explore regularization techniques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "JLpLa8Jt7Vu4"
   },
   "outputs": [],
   "source": [
    "# These are all the modules we'll be using later. Make sure you can import them\n",
    "# before proceeding further.\n",
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from six.moves import cPickle as pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HrCK6e17WzV"
   },
   "source": [
    "First reload the data we generated in _notmist.ipynb_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11777,
     "status": "ok",
     "timestamp": 1449849322348,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "y3-cj1bpmuxc",
    "outputId": "e03576f1-ebbe-4838-c388-f1777bcc9873"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 28, 28) (200000,)\n",
      "Validation set (10000, 28, 28) (10000,)\n",
      "Test set (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "pickle_file = 'data/notMNIST.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "  save = pickle.load(f)\n",
    "  train_dataset = save['train_dataset']\n",
    "  train_labels = save['train_labels']\n",
    "  valid_dataset = save['valid_dataset']\n",
    "  valid_labels = save['valid_labels']\n",
    "  test_dataset = save['test_dataset']\n",
    "  test_labels = save['test_labels']\n",
    "  del save  # hint to help gc free up memory\n",
    "  print('Training set', train_dataset.shape, train_labels.shape)\n",
    "  print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "  print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L7aHrm6nGDMB"
   },
   "source": [
    "Reformat into a shape that's more adapted to the models we're going to train:\n",
    "- data as a flat matrix,\n",
    "- labels as float 1-hot encodings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "output_extras": [
      {
       "item_id": 1
      }
     ]
    },
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": {
     "elapsed": 11728,
     "status": "ok",
     "timestamp": 1449849322356,
     "user": {
      "color": "",
      "displayName": "",
      "isAnonymous": false,
      "isMe": true,
      "permissionId": "",
      "photoUrl": "",
      "sessionId": "0",
      "userId": ""
     },
     "user_tz": 480
    },
    "id": "IRSyYiIIGIzS",
    "outputId": "3f8996ee-3574-4f44-c953-5c8a04636582"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (200000, 784) (200000, 10)\n",
      "Validation set (10000, 784) (10000, 10)\n",
      "Test set (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "image_size = 28\n",
    "num_labels = 10\n",
    "\n",
    "def reformat(dataset, labels):\n",
    "  dataset = dataset.reshape((-1, image_size * image_size)).astype(np.float32)\n",
    "  # Map 2 to [0.0, 1.0, 0.0 ...], 3 to [0.0, 0.0, 1.0 ...]\n",
    "  labels = (np.arange(num_labels) == labels[:,None]).astype(np.float32)\n",
    "  return dataset, labels\n",
    "train_dataset, train_labels = reformat(train_dataset, train_labels)\n",
    "valid_dataset, valid_labels = reformat(valid_dataset, valid_labels)\n",
    "test_dataset, test_labels = reformat(test_dataset, test_labels)\n",
    "print('Training set', train_dataset.shape, train_labels.shape)\n",
    "print('Validation set', valid_dataset.shape, valid_labels.shape)\n",
    "print('Test set', test_dataset.shape, test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "both",
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "RajPLaL_ZW6w"
   },
   "outputs": [],
   "source": [
    "def accuracy(predictions, labels):\n",
    "  return (100.0 * np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))\n",
    "          / predictions.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sgLbUAQ1CW-1"
   },
   "source": [
    "---\n",
    "Problem 1\n",
    "---------\n",
    "\n",
    "Introduce and tune L2 regularization for both logistic and neural network models. Remember that L2 amounts to adding a penalty on the norm of the weights to the loss. In TensorFlow, you can compute the L2 loss for a tensor `t` using `nn.l2_loss(t)`. The right amount of regularization should improve your validation / test accuracy.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "hnodes = 1024\n",
    "\n",
    "beta1 = .001\n",
    "beta2 = .005\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, hnodes]))\n",
    "  biases1 = tf.Variable(tf.zeros([hnodes]))\n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([hnodes, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  logits = tf.matmul(hidden, weights2) + biases2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  new_loss = loss + beta1 * tf.nn.l2_loss(weights1) + beta2 * tf.nn.l2_loss(weights2)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(new_loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_hidden = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(valid_hidden, weights2) + biases2)\n",
    "  test_hidden = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(test_hidden, weights2) + biases2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_steps = 3001\n",
    "\n",
    "def do_sgd():\n",
    "    with tf.Session(graph=graph) as session:\n",
    "      tf.initialize_all_variables().run()\n",
    "      print(\"Initialized\")\n",
    "      for step in range(num_steps):\n",
    "        # Pick an offset within the training data, which has been randomized.\n",
    "        # Note: we could use better randomization across epochs.\n",
    "        offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "        # Generate a minibatch.\n",
    "        batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "        batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "        # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "        # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "        # and the value is the numpy array to feed to it.\n",
    "        feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "        _, l, predictions = session.run(\n",
    "          [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "        if (step % 500 == 0):\n",
    "          print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "          print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "          print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "            valid_prediction.eval(), valid_labels))\n",
    "      print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 373.208374\n",
      "Minibatch accuracy: 9.4%\n",
      "Validation accuracy: 32.1%\n",
      "Minibatch loss at step 500: 8.690955\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 1000: 1.918769\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1500: 0.924422\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 2000: 0.482348\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 84.2%\n",
      "Minibatch loss at step 2500: 0.542456\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 85.6%\n",
      "Minibatch loss at step 3000: 0.425517\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 86.0%\n",
      "Test accuracy: 92.9%\n"
     ]
    }
   ],
   "source": [
    "do_sgd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "na8xX2yHZzNF"
   },
   "source": [
    "---\n",
    "Problem 2\n",
    "---------\n",
    "Let's demonstrate an extreme case of overfitting. Restrict your training data to just a few batches. What happens?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 306.987793\n",
      "Minibatch accuracy: 7.8%\n",
      "Validation accuracy: 27.6%\n",
      "Minibatch loss at step 500: 0.000528\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 1000: 0.002233\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 1500: 0.004715\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 2000: 0.014190\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 2500: 0.016965\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 3000: 0.018546\n",
      "Minibatch accuracy: 100.0%\n",
      "Validation accuracy: 79.8%\n",
      "Test accuracy: 87.4%\n"
     ]
    }
   ],
   "source": [
    "nbatches = train_labels.shape[0] / batch_size\n",
    "limit_batch = nbatches - 10\n",
    "\n",
    "with tf.Session(graph=graph) as session:\n",
    "  tf.initialize_all_variables().run()\n",
    "  print(\"Initialized\")\n",
    "  for step in range(num_steps):\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - (batch_size * limit_batch))\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run(\n",
    "      [optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 500 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      print(\"Validation accuracy: %.1f%%\" % accuracy(\n",
    "        valid_prediction.eval(), valid_labels))\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ww3SCBUdlkRc"
   },
   "source": [
    "---\n",
    "Problem 3\n",
    "---------\n",
    "Introduce Dropout on the hidden layer of the neural network. Remember: Dropout should only be introduced during training, not evaluation, otherwise your evaluation results would be stochastic as well. TensorFlow provides `nn.dropout()` for that, but you have to make sure it's only inserted during training.\n",
    "\n",
    "What happens to our extreme overfitting case?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 446.617126\n",
      "Minibatch accuracy: 12.5%\n",
      "Validation accuracy: 28.7%\n",
      "Minibatch loss at step 500: 31.030727\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 1000: 3.275347\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1500: 1.327454\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2000: 0.799311\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 83.0%\n",
      "Minibatch loss at step 2500: 0.766142\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 83.9%\n",
      "Minibatch loss at step 3000: 0.533667\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 84.8%\n",
      "Test accuracy: 91.5%\n"
     ]
    }
   ],
   "source": [
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  weights1 = tf.Variable(\n",
    "    tf.truncated_normal([image_size * image_size, hnodes]))\n",
    "  biases1 = tf.Variable(tf.zeros([hnodes]))\n",
    "  weights2 = tf.Variable(\n",
    "    tf.truncated_normal([hnodes, num_labels]))\n",
    "  biases2 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  hidden = tf.nn.relu(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  logits = tf.matmul(tf.nn.dropout(hidden, .5), weights2) + biases2\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  new_loss = loss + beta1 * tf.nn.l2_loss(weights1) + beta2 * tf.nn.l2_loss(weights2)\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(0.5).minimize(new_loss)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  valid_hidden = tf.nn.relu(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(valid_hidden, weights2) + biases2)\n",
    "  test_hidden = tf.nn.relu(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(test_hidden, weights2) + biases2)\n",
    "    \n",
    "do_sgd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-b1hTz3VWZjw"
   },
   "source": [
    "---\n",
    "Problem 4\n",
    "---------\n",
    "\n",
    "Try to get the best performance you can using a multi-layer model! The best reported test accuracy using a deep network is [97.1%](http://yaroslavvb.blogspot.com/2011/09/notmnist-dataset.html?showComment=1391023266211#c8758720086795711595).\n",
    "\n",
    "One avenue you can explore is to add multiple layers.\n",
    "\n",
    "Another one is to use learning rate decay:\n",
    "\n",
    "    global_step = tf.Variable(0)  # count the number of steps taken.\n",
    "    learning_rate = tf.train.exponential_decay(0.5, global_step, ...)\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss, global_step=global_step)\n",
    " \n",
    " ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with network of 3 hidden layers of sizes 1024, 300 and 50 with tanh activations, with dropout on the hidden activations, learning rate decay and early stopping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "hnodes1 = 1024\n",
    "hnodes2 = 300\n",
    "hnodes3 = 50\n",
    "\n",
    "beta1 = .01\n",
    "beta2 = .01\n",
    "beta3 = .03\n",
    "beta4 = .05\n",
    "\n",
    "dropout = True\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "  # Input data. For the training data, we use a placeholder that will be fed\n",
    "  # at run time with a training minibatch.\n",
    "  tf_train_dataset = tf.placeholder(tf.float32,\n",
    "                                    shape=(batch_size, image_size * image_size))\n",
    "  tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, num_labels))\n",
    "  tf_valid_dataset = tf.constant(valid_dataset)\n",
    "  tf_test_dataset = tf.constant(test_dataset)\n",
    "  \n",
    "  # Variables.\n",
    "  global_step = tf.Variable(0, trainable=False)\n",
    "  learning_rate = tf.train.exponential_decay(0.5, global_step, 100000, 0.96)\n",
    "  weights1 = tf.Variable(tf.truncated_normal([image_size * image_size, hnodes1]))\n",
    "  biases1 = tf.Variable(tf.zeros([hnodes1]))\n",
    "  weights2 = tf.Variable(tf.truncated_normal([hnodes1, hnodes2]))\n",
    "  biases2 = tf.Variable(tf.zeros([hnodes2]))\n",
    "  weights3 = tf.Variable(tf.truncated_normal([hnodes2, hnodes3]))\n",
    "  biases3 = tf.Variable(tf.zeros([hnodes3]))\n",
    "  weights4 = tf.Variable(tf.truncated_normal([hnodes3, num_labels]))\n",
    "  biases4 = tf.Variable(tf.zeros([num_labels]))\n",
    "  \n",
    "  # Training computation.\n",
    "  hidden1 = tf.nn.tanh(tf.matmul(tf_train_dataset, weights1) + biases1)\n",
    "  if dropout:\n",
    "    hidden2 = tf.nn.tanh(tf.matmul(tf.nn.dropout(hidden1, .5), weights2) + biases2)  \n",
    "    hidden3 = tf.nn.tanh(tf.matmul(tf.nn.dropout(hidden2, .5), weights3) + biases3)\n",
    "    logits = tf.matmul(tf.nn.dropout(hidden3, .5), weights4) + biases4\n",
    "  else:\n",
    "    hidden2 = tf.nn.tanh(tf.matmul(hidden1, weights2) + biases2)  \n",
    "    hidden3 = tf.nn.tanh(tf.matmul(hidden2, weights3) + biases3)\n",
    "    logits = tf.matmul(hidden3, weights4) + biases4\n",
    "  loss = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(logits, tf_train_labels))\n",
    "  new_loss = (loss + beta1 * tf.nn.l2_loss(weights1) +\n",
    "    beta2 * tf.nn.l2_loss(weights2) + beta3 * tf.nn.l2_loss(weights3) +\n",
    "    beta4 * tf.nn.l2_loss(weights4))\n",
    "  \n",
    "  # Optimizer.\n",
    "  optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(new_loss, global_step=global_step)\n",
    "  \n",
    "  # Predictions for the training, validation, and test data.\n",
    "  train_prediction = tf.nn.softmax(logits)\n",
    "  \n",
    "  valid_hidden1 = tf.nn.tanh(tf.matmul(tf_valid_dataset, weights1) + biases1)\n",
    "  valid_hidden2 = tf.nn.tanh(tf.matmul(valid_hidden1, weights2) + biases2)\n",
    "  valid_hidden3 = tf.nn.tanh(tf.matmul(valid_hidden2, weights3) + biases3)\n",
    "  valid_prediction = tf.nn.softmax(tf.matmul(valid_hidden3, weights4) + biases4)\n",
    "  \n",
    "  test_hidden1 = tf.nn.tanh(tf.matmul(tf_test_dataset, weights1) + biases1)\n",
    "  test_hidden2 = tf.nn.tanh(tf.matmul(test_hidden1, weights2) + biases2)\n",
    "  test_hidden3 = tf.nn.tanh(tf.matmul(test_hidden2, weights3) + biases3)\n",
    "  test_prediction = tf.nn.softmax(tf.matmul(test_hidden3, weights4) + biases4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch loss at step 0: 13.191300\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 13.4%\n",
      "Minibatch loss at step 5: 10.226584\n",
      "Minibatch accuracy: 14.8%\n",
      "Validation accuracy: 20.2%\n",
      "Minibatch loss at step 10: 7.188357\n",
      "Minibatch accuracy: 10.9%\n",
      "Validation accuracy: 24.8%\n",
      "Minibatch loss at step 15: 5.060424\n",
      "Minibatch accuracy: 24.2%\n",
      "Validation accuracy: 28.8%\n",
      "Minibatch loss at step 20: 3.652320\n",
      "Minibatch accuracy: 24.2%\n",
      "Validation accuracy: 33.4%\n",
      "Minibatch loss at step 25: 3.401240\n",
      "Minibatch accuracy: 11.7%\n",
      "Validation accuracy: 40.5%\n",
      "Minibatch loss at step 30: 2.897736\n",
      "Minibatch accuracy: 14.1%\n",
      "Validation accuracy: 44.4%\n",
      "Minibatch loss at step 35: 2.422002\n",
      "Minibatch accuracy: 15.6%\n",
      "Validation accuracy: 43.8%\n",
      "Minibatch loss at step 40: 2.210923\n",
      "Minibatch accuracy: 17.2%\n",
      "Validation accuracy: 48.0%\n",
      "Minibatch loss at step 45: 2.121631\n",
      "Minibatch accuracy: 25.0%\n",
      "Validation accuracy: 47.1%\n",
      "Minibatch loss at step 50: 2.124248\n",
      "Minibatch accuracy: 23.4%\n",
      "Validation accuracy: 49.2%\n",
      "Minibatch loss at step 55: 2.165711\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 48.5%\n",
      "Minibatch loss at step 60: 2.055749\n",
      "Minibatch accuracy: 21.9%\n",
      "Validation accuracy: 49.6%\n",
      "Minibatch loss at step 65: 2.143508\n",
      "Minibatch accuracy: 20.3%\n",
      "Validation accuracy: 52.9%\n",
      "Minibatch loss at step 70: 2.134064\n",
      "Minibatch accuracy: 24.2%\n",
      "Validation accuracy: 53.1%\n",
      "Minibatch loss at step 75: 2.002305\n",
      "Minibatch accuracy: 27.3%\n",
      "Validation accuracy: 48.6%\n",
      "Minibatch loss at step 80: 1.997682\n",
      "Minibatch accuracy: 28.9%\n",
      "Validation accuracy: 52.0%\n",
      "Minibatch loss at step 85: 1.994701\n",
      "Minibatch accuracy: 22.7%\n",
      "Validation accuracy: 53.1%\n",
      "Minibatch loss at step 90: 1.992761\n",
      "Minibatch accuracy: 36.7%\n",
      "Validation accuracy: 53.6%\n",
      "Minibatch loss at step 95: 1.980114\n",
      "Minibatch accuracy: 26.6%\n",
      "Validation accuracy: 51.9%\n",
      "Minibatch loss at step 100: 1.936961\n",
      "Minibatch accuracy: 31.2%\n",
      "Validation accuracy: 52.1%\n",
      "Minibatch loss at step 105: 1.890399\n",
      "Minibatch accuracy: 33.6%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 110: 1.898299\n",
      "Minibatch accuracy: 32.0%\n",
      "Validation accuracy: 56.4%\n",
      "Minibatch loss at step 115: 1.950766\n",
      "Minibatch accuracy: 28.9%\n",
      "Validation accuracy: 59.3%\n",
      "Minibatch loss at step 120: 1.944995\n",
      "Minibatch accuracy: 32.8%\n",
      "Validation accuracy: 56.5%\n",
      "Minibatch loss at step 125: 1.848071\n",
      "Minibatch accuracy: 38.3%\n",
      "Validation accuracy: 58.5%\n",
      "Minibatch loss at step 130: 1.836673\n",
      "Minibatch accuracy: 33.6%\n",
      "Validation accuracy: 58.1%\n",
      "Minibatch loss at step 135: 1.842285\n",
      "Minibatch accuracy: 35.2%\n",
      "Validation accuracy: 57.3%\n",
      "Minibatch loss at step 140: 1.790238\n",
      "Minibatch accuracy: 35.9%\n",
      "Validation accuracy: 63.0%\n",
      "Minibatch loss at step 145: 1.651686\n",
      "Minibatch accuracy: 45.3%\n",
      "Validation accuracy: 65.4%\n",
      "Minibatch loss at step 150: 1.673710\n",
      "Minibatch accuracy: 43.0%\n",
      "Validation accuracy: 63.0%\n",
      "Minibatch loss at step 155: 1.695192\n",
      "Minibatch accuracy: 45.3%\n",
      "Validation accuracy: 61.9%\n",
      "Minibatch loss at step 160: 1.613387\n",
      "Minibatch accuracy: 46.9%\n",
      "Validation accuracy: 65.9%\n",
      "Minibatch loss at step 165: 1.584755\n",
      "Minibatch accuracy: 43.8%\n",
      "Validation accuracy: 64.3%\n",
      "Minibatch loss at step 170: 1.689477\n",
      "Minibatch accuracy: 41.4%\n",
      "Validation accuracy: 67.5%\n",
      "Minibatch loss at step 175: 1.553963\n",
      "Minibatch accuracy: 46.1%\n",
      "Validation accuracy: 68.0%\n",
      "Minibatch loss at step 180: 1.620805\n",
      "Minibatch accuracy: 46.1%\n",
      "Validation accuracy: 70.0%\n",
      "Minibatch loss at step 185: 1.629911\n",
      "Minibatch accuracy: 48.4%\n",
      "Validation accuracy: 68.7%\n",
      "Minibatch loss at step 190: 1.421728\n",
      "Minibatch accuracy: 52.3%\n",
      "Validation accuracy: 65.1%\n",
      "Minibatch loss at step 195: 1.375625\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 71.4%\n",
      "Minibatch loss at step 200: 1.380164\n",
      "Minibatch accuracy: 57.0%\n",
      "Validation accuracy: 68.4%\n",
      "Minibatch loss at step 205: 1.457244\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 71.0%\n",
      "Minibatch loss at step 210: 1.564416\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 69.7%\n",
      "Minibatch loss at step 215: 1.324647\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 72.7%\n",
      "Minibatch loss at step 220: 1.427741\n",
      "Minibatch accuracy: 59.4%\n",
      "Validation accuracy: 72.4%\n",
      "Minibatch loss at step 225: 1.387074\n",
      "Minibatch accuracy: 54.7%\n",
      "Validation accuracy: 69.0%\n",
      "Minibatch loss at step 230: 1.446661\n",
      "Minibatch accuracy: 53.1%\n",
      "Validation accuracy: 72.2%\n",
      "Minibatch loss at step 235: 1.212712\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 71.5%\n",
      "Minibatch loss at step 240: 1.366357\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 73.3%\n",
      "Minibatch loss at step 245: 1.420852\n",
      "Minibatch accuracy: 53.9%\n",
      "Validation accuracy: 73.9%\n",
      "Minibatch loss at step 250: 1.153801\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 71.4%\n",
      "Minibatch loss at step 255: 1.342308\n",
      "Minibatch accuracy: 56.2%\n",
      "Validation accuracy: 73.6%\n",
      "Minibatch loss at step 260: 1.238972\n",
      "Minibatch accuracy: 63.3%\n",
      "Validation accuracy: 70.4%\n",
      "Minibatch loss at step 265: 1.300714\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 74.8%\n",
      "Minibatch loss at step 270: 1.370784\n",
      "Minibatch accuracy: 62.5%\n",
      "Validation accuracy: 71.1%\n",
      "Minibatch loss at step 275: 1.247531\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 72.2%\n",
      "Minibatch loss at step 280: 1.215275\n",
      "Minibatch accuracy: 60.9%\n",
      "Validation accuracy: 74.2%\n",
      "Minibatch loss at step 285: 1.176268\n",
      "Minibatch accuracy: 65.6%\n",
      "Validation accuracy: 74.3%\n",
      "Minibatch loss at step 290: 1.135699\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 75.5%\n",
      "Minibatch loss at step 295: 1.313107\n",
      "Minibatch accuracy: 58.6%\n",
      "Validation accuracy: 75.4%\n",
      "Minibatch loss at step 300: 1.361999\n",
      "Minibatch accuracy: 55.5%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 305: 1.097633\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 75.9%\n",
      "Minibatch loss at step 310: 1.193339\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 76.1%\n",
      "Minibatch loss at step 315: 1.067422\n",
      "Minibatch accuracy: 68.8%\n",
      "Validation accuracy: 75.0%\n",
      "Minibatch loss at step 320: 1.197638\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 76.4%\n",
      "Minibatch loss at step 325: 1.090793\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 76.9%\n",
      "Minibatch loss at step 330: 1.141018\n",
      "Minibatch accuracy: 64.1%\n",
      "Validation accuracy: 76.2%\n",
      "Minibatch loss at step 335: 1.054783\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 77.6%\n",
      "Minibatch loss at step 340: 1.011154\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 76.7%\n",
      "Minibatch loss at step 345: 0.938260\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.6%\n",
      "Minibatch loss at step 350: 1.151066\n",
      "Minibatch accuracy: 64.8%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 355: 1.014410\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 76.3%\n",
      "Minibatch loss at step 360: 1.079376\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.2%\n",
      "Minibatch loss at step 365: 1.157154\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 370: 1.215634\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 375: 1.055028\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 77.8%\n",
      "Minibatch loss at step 380: 0.921231\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 385: 1.076168\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 78.1%\n",
      "Minibatch loss at step 390: 1.129660\n",
      "Minibatch accuracy: 67.2%\n",
      "Validation accuracy: 78.4%\n",
      "Minibatch loss at step 395: 1.103424\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 400: 1.124606\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 405: 1.099483\n",
      "Minibatch accuracy: 68.0%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 410: 1.152062\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 78.0%\n",
      "Minibatch loss at step 415: 0.905237\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.6%\n",
      "Minibatch loss at step 420: 0.929668\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 425: 0.957693\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 430: 0.967150\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 435: 0.966021\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 440: 0.922100\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 445: 0.871534\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 78.3%\n",
      "Minibatch loss at step 450: 0.863109\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 455: 0.905465\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 460: 0.959045\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 465: 0.829361\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 470: 0.956088\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 475: 0.792888\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 480: 0.963107\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 485: 0.874217\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 490: 1.164172\n",
      "Minibatch accuracy: 66.4%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 495: 0.872282\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 500: 0.989044\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 505: 0.985039\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 510: 0.987274\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 515: 1.037098\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 520: 0.936820\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 525: 1.025276\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 530: 0.799368\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 535: 0.854006\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 540: 0.835301\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 545: 0.762894\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 550: 0.987966\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 555: 1.030432\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 560: 0.787217\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 565: 0.894660\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 570: 0.750590\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 575: 0.924535\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 580: 0.725717\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 585: 1.020139\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 590: 1.004710\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 595: 0.685847\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 600: 0.968363\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 605: 1.002714\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 610: 0.688648\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 615: 0.657467\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 620: 1.046131\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 625: 0.930907\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 630: 0.777749\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 635: 0.740838\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 640: 0.791170\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 645: 0.812223\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 650: 0.741708\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 655: 0.737973\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 660: 0.688296\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 665: 0.775950\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 670: 0.809196\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 675: 0.971919\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 680: 0.808553\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 685: 0.723501\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 690: 0.627187\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 695: 0.755177\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 700: 0.768244\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 705: 0.842326\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 710: 0.713642\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 715: 0.873171\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 720: 0.842396\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 725: 0.831465\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 730: 0.933649\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 735: 0.850590\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 740: 0.854789\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 745: 0.753452\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 750: 0.854842\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 755: 0.886697\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 760: 0.803719\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 765: 0.539900\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 770: 0.902898\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 775: 1.000527\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 780: 0.959271\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 785: 0.853067\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 790: 0.802519\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 795: 0.778615\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 800: 0.970775\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 805: 0.648830\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 810: 0.782288\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 815: 0.838154\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 820: 0.695896\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 825: 0.709011\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.3%\n",
      "Minibatch loss at step 830: 0.924772\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 835: 0.730689\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 840: 0.804230\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 845: 0.693072\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 850: 0.788140\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 855: 0.879226\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 860: 0.988569\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 865: 0.852858\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 870: 0.754473\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 875: 0.836149\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 880: 0.805745\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 885: 0.704098\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 890: 0.857486\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 895: 0.834423\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 900: 0.811864\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 905: 0.807930\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 910: 0.663482\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 915: 0.822986\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 920: 1.012657\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 925: 0.699217\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 930: 0.832654\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 935: 0.788049\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 940: 0.837340\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 945: 0.981399\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 950: 0.780549\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 955: 0.766487\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 960: 0.734573\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 965: 0.736048\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 970: 0.986297\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 975: 0.689138\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 980: 0.709911\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 985: 0.809822\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 990: 0.860448\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 78.5%\n",
      "Minibatch loss at step 995: 0.920759\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1000: 0.735157\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1005: 0.769557\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1010: 0.831699\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1015: 1.018040\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1020: 0.780645\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1025: 0.870088\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1030: 0.931263\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 1035: 1.036409\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1040: 0.740993\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1045: 0.896482\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1050: 0.890852\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1055: 0.774775\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1060: 0.744812\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1065: 0.828086\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1070: 0.837986\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1075: 0.788061\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1080: 0.993488\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1085: 0.843636\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1090: 0.716095\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1095: 0.771846\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1100: 0.954062\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1105: 0.708680\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1110: 0.873417\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1115: 0.819432\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1120: 0.782703\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1125: 0.960212\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1130: 0.817306\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1135: 0.801710\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1140: 0.710881\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1145: 0.689096\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1150: 0.791610\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1155: 0.809081\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1160: 1.084835\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1165: 0.953023\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1170: 0.930530\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1175: 0.890135\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1180: 0.991785\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1185: 0.875571\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1190: 0.742025\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1195: 0.855793\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1200: 0.692478\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1205: 0.995255\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1210: 0.822714\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1215: 0.882519\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1220: 0.904658\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1225: 0.811508\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1230: 0.708043\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1235: 0.796845\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1240: 0.848625\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1245: 0.818256\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1250: 0.860470\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1255: 0.888002\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 1260: 0.883948\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1265: 0.588994\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1270: 0.830061\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1275: 0.967574\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1280: 0.771320\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1285: 0.677115\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1290: 0.745089\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1295: 0.876629\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1300: 0.777020\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1305: 0.921936\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1310: 0.807510\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 77.3%\n",
      "Minibatch loss at step 1315: 0.669993\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1320: 0.685880\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1325: 0.912360\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 1330: 0.923661\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1335: 0.680788\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1340: 0.817682\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1345: 0.842310\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1350: 0.824277\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1355: 0.807943\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1360: 0.821813\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 79.4%\n",
      "Minibatch loss at step 1365: 0.729774\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 1370: 0.643830\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 1375: 0.823336\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1380: 0.806249\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1385: 0.906095\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1390: 0.836109\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1395: 0.947259\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1400: 0.817006\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1405: 0.767373\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1410: 0.789230\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1415: 0.800446\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1420: 0.704372\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1425: 0.912672\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1430: 0.717552\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1435: 0.967458\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1440: 0.789216\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.0%\n",
      "Minibatch loss at step 1445: 0.937027\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1450: 0.929784\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1455: 0.868133\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1460: 0.816092\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1465: 0.694238\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1470: 0.863500\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1475: 0.803005\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1480: 0.881106\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1485: 0.837500\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1490: 0.777833\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1495: 0.679238\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1500: 0.766331\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1505: 0.774525\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1510: 0.797168\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1515: 0.785250\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1520: 0.869157\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1525: 0.796937\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1530: 0.821988\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1535: 0.914270\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1540: 0.801826\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1545: 0.723394\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1550: 0.848315\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1555: 0.834349\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1560: 0.845648\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1565: 1.002581\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1570: 0.885188\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1575: 0.894016\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1580: 0.860781\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1585: 0.785708\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1590: 1.000801\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1595: 0.654397\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1600: 0.753937\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 1605: 0.864848\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1610: 0.778203\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1615: 0.962904\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1620: 0.604828\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1625: 0.644562\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1630: 0.778894\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1635: 0.874197\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1640: 0.708845\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1645: 0.727239\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1650: 1.023378\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1655: 0.768877\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1660: 0.612500\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1665: 0.695392\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1670: 0.831287\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1675: 0.826683\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1680: 0.838849\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1685: 0.833435\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1690: 0.829944\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 1695: 0.858865\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1700: 0.859620\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1705: 0.718687\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1710: 0.670715\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1715: 0.825897\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1720: 0.773750\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1725: 0.884670\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 1730: 0.863962\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1735: 0.677181\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1740: 0.800161\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 78.9%\n",
      "Minibatch loss at step 1745: 0.909380\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 1750: 0.828462\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1755: 0.687474\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1760: 0.735034\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 1765: 0.730342\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1770: 0.759619\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1775: 0.788118\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1780: 0.858490\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1785: 0.904305\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1790: 0.780896\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 1795: 0.846679\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1800: 0.769273\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1805: 0.921706\n",
      "Minibatch accuracy: 71.9%\n",
      "Validation accuracy: 79.1%\n",
      "Minibatch loss at step 1810: 0.666573\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 1815: 0.854314\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1820: 0.839580\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1825: 0.848822\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 1830: 0.704825\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1835: 0.778554\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1840: 0.653961\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1845: 1.071864\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 1850: 0.851412\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.2%\n",
      "Minibatch loss at step 1855: 0.795585\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1860: 0.815368\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1865: 0.740663\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1870: 0.850356\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1875: 0.760945\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 1880: 0.652341\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1885: 0.826802\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1890: 1.032592\n",
      "Minibatch accuracy: 69.5%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 1895: 0.971955\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1900: 0.709906\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 1905: 0.902107\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1910: 0.849801\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1915: 0.763422\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1920: 0.893863\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 1925: 0.696881\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1930: 0.763194\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1935: 0.779752\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 1940: 0.773046\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1945: 0.878546\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1950: 0.814595\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 1955: 0.646606\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 1960: 0.772015\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 1965: 0.849798\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 1970: 0.772172\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 1975: 0.809032\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 1980: 0.801046\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 1985: 0.685016\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 1990: 0.961815\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 1995: 0.781145\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2000: 0.794311\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2005: 0.956811\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2010: 0.814505\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2015: 1.071745\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2020: 0.934159\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2025: 0.748117\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2030: 0.657807\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2035: 0.852218\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2040: 0.824228\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2045: 0.752579\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2050: 0.954008\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2055: 0.855520\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2060: 0.774277\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2065: 0.845019\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2070: 0.936074\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2075: 1.067197\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2080: 0.743879\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2085: 0.648657\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2090: 0.877259\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2095: 0.764468\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2100: 0.699916\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2105: 0.884280\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2110: 0.816820\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2115: 0.798325\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2120: 0.897602\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2125: 0.876318\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2130: 0.863981\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2135: 0.878071\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2140: 0.758047\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2145: 0.856040\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2150: 0.882353\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2155: 0.915515\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2160: 0.929319\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2165: 0.685222\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2170: 0.805405\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2175: 0.945571\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.8%\n",
      "Minibatch loss at step 2180: 0.756845\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2185: 0.797033\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2190: 0.891848\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2195: 0.834856\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2200: 0.996097\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2205: 0.783363\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2210: 0.908168\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2215: 0.962941\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2220: 0.944827\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2225: 0.977761\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2230: 0.879904\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2235: 0.826686\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2240: 0.753622\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2245: 0.835339\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2250: 0.580075\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2255: 0.831730\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2260: 0.768140\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 79.5%\n",
      "Minibatch loss at step 2265: 0.754907\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2270: 1.028615\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 79.6%\n",
      "Minibatch loss at step 2275: 0.895036\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2280: 0.776077\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2285: 0.719546\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2290: 0.809314\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2295: 0.811739\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.8%\n",
      "Minibatch loss at step 2300: 0.923587\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2305: 0.699971\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2310: 0.785213\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2315: 0.843948\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2320: 0.667277\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2325: 0.699300\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2330: 0.854123\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2335: 0.774651\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2340: 0.834552\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2345: 0.770687\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2350: 0.632125\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2355: 0.837369\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2360: 0.783907\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2365: 0.757974\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2370: 0.882477\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.1%\n",
      "Minibatch loss at step 2375: 0.787864\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2380: 0.899191\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2385: 0.936796\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2390: 0.763449\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2395: 0.701818\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2400: 0.852473\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2405: 0.942080\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2410: 0.661708\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2415: 0.738519\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2420: 0.765414\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2425: 0.781854\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2430: 0.869830\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2435: 0.717083\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2440: 0.744516\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2445: 0.903633\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2450: 0.735572\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 78.7%\n",
      "Minibatch loss at step 2455: 0.758341\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2460: 0.675465\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2465: 0.845142\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2470: 0.876773\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2475: 0.923586\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2480: 0.886811\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2485: 0.939398\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2490: 0.771844\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2495: 0.773546\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2500: 0.936996\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2505: 0.789913\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2510: 0.913433\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2515: 0.925324\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2520: 0.922411\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2525: 0.764319\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2530: 0.886251\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2535: 0.754664\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2540: 0.768643\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2545: 0.884308\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2550: 0.775951\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2555: 0.766530\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2560: 0.834861\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2565: 0.887713\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2570: 0.829892\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2575: 0.662442\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2580: 0.919340\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2585: 0.765629\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2590: 0.673946\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 82.0%\n",
      "Minibatch loss at step 2595: 0.809569\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2600: 1.049384\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2605: 0.759544\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2610: 0.854972\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2615: 0.685973\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2620: 0.820107\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2625: 0.765743\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2630: 0.740317\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2635: 0.652856\n",
      "Minibatch accuracy: 88.3%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2640: 0.734736\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2645: 0.771172\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2650: 0.978092\n",
      "Minibatch accuracy: 71.1%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2655: 0.815119\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2660: 1.028110\n",
      "Minibatch accuracy: 70.3%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2665: 0.724119\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2670: 0.817449\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2675: 0.824008\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2680: 0.936584\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2685: 0.750186\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2690: 0.771350\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2695: 0.864244\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2700: 0.870131\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2705: 0.852122\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2710: 0.669831\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2715: 0.777106\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 79.9%\n",
      "Minibatch loss at step 2720: 0.624391\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2725: 0.588693\n",
      "Minibatch accuracy: 89.1%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2730: 0.788308\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2735: 0.680613\n",
      "Minibatch accuracy: 86.7%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2740: 0.677123\n",
      "Minibatch accuracy: 85.2%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2745: 0.757595\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2750: 0.866259\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.7%\n",
      "Minibatch loss at step 2755: 0.950726\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2760: 0.759874\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2765: 0.856616\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2770: 0.827254\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 79.7%\n",
      "Minibatch loss at step 2775: 0.780334\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2780: 0.910951\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2785: 1.006844\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2790: 0.776345\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2795: 0.673468\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2800: 0.808612\n",
      "Minibatch accuracy: 83.6%\n",
      "Validation accuracy: 80.4%\n",
      "Minibatch loss at step 2805: 0.655674\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2810: 0.808902\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 80.6%\n",
      "Minibatch loss at step 2815: 0.869191\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2820: 0.798460\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.7%\n",
      "Minibatch loss at step 2825: 0.642136\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2830: 0.866760\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2835: 0.737171\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2840: 0.825562\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2845: 0.608591\n",
      "Minibatch accuracy: 87.5%\n",
      "Validation accuracy: 81.9%\n",
      "Minibatch loss at step 2850: 1.004535\n",
      "Minibatch accuracy: 74.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2855: 0.782852\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2860: 0.685444\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2865: 0.737906\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2870: 0.771406\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2875: 0.838995\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2880: 0.691670\n",
      "Minibatch accuracy: 79.7%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2885: 0.688334\n",
      "Minibatch accuracy: 84.4%\n",
      "Validation accuracy: 81.3%\n",
      "Minibatch loss at step 2890: 0.950724\n",
      "Minibatch accuracy: 73.4%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2895: 0.768642\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2900: 0.818169\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2905: 0.723287\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2910: 0.705311\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2915: 1.082800\n",
      "Minibatch accuracy: 72.7%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2920: 0.995510\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 81.6%\n",
      "Minibatch loss at step 2925: 0.841073\n",
      "Minibatch accuracy: 78.1%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2930: 0.766889\n",
      "Minibatch accuracy: 77.3%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2935: 0.899406\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.5%\n",
      "Minibatch loss at step 2940: 0.848306\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.3%\n",
      "Minibatch loss at step 2945: 0.738108\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.0%\n",
      "Minibatch loss at step 2950: 0.847151\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.9%\n",
      "Minibatch loss at step 2955: 0.828122\n",
      "Minibatch accuracy: 80.5%\n",
      "Validation accuracy: 81.1%\n",
      "Minibatch loss at step 2960: 0.650614\n",
      "Minibatch accuracy: 85.9%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2965: 0.720753\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 80.2%\n",
      "Minibatch loss at step 2970: 0.809656\n",
      "Minibatch accuracy: 75.0%\n",
      "Validation accuracy: 80.8%\n",
      "Minibatch loss at step 2975: 0.702084\n",
      "Minibatch accuracy: 82.0%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 2980: 0.784277\n",
      "Minibatch accuracy: 81.2%\n",
      "Validation accuracy: 81.5%\n",
      "Minibatch loss at step 2985: 0.693208\n",
      "Minibatch accuracy: 82.8%\n",
      "Validation accuracy: 81.2%\n",
      "Minibatch loss at step 2990: 1.063412\n",
      "Minibatch accuracy: 75.8%\n",
      "Validation accuracy: 80.0%\n",
      "Minibatch loss at step 2995: 1.005107\n",
      "Minibatch accuracy: 76.6%\n",
      "Validation accuracy: 81.4%\n",
      "Minibatch loss at step 3000: 0.695824\n",
      "Minibatch accuracy: 78.9%\n",
      "Validation accuracy: 80.3%\n",
      "Test accuracy: 87.4%\n"
     ]
    }
   ],
   "source": [
    "num_steps = 3001\n",
    "with tf.Session(graph=graph) as session:\n",
    "  init_ops = tf.initialize_all_variables()\n",
    "  session.run(init_ops)\n",
    "  print(\"Initialized\")\n",
    "  valid_accuracy = 0\n",
    "  for step in range(num_steps):\n",
    "    params = {\n",
    "        'weights1': weights1.eval(),\n",
    "        'weights2': weights2.eval(),\n",
    "        'weights3': weights3.eval(),\n",
    "        'weights4': weights4.eval(),\n",
    "        'biases1': biases1.eval(),\n",
    "        'biases2': biases2.eval(),\n",
    "        'biases3': biases3.eval(),\n",
    "        'biases4': biases4.eval()\n",
    "    }\n",
    "    # Pick an offset within the training data, which has been randomized.\n",
    "    # Note: we could use better randomization across epochs.\n",
    "    offset = (step * batch_size) % (train_labels.shape[0] - batch_size)\n",
    "    # Generate a minibatch.\n",
    "    batch_data = train_dataset[offset:(offset + batch_size), :]\n",
    "    batch_labels = train_labels[offset:(offset + batch_size), :]\n",
    "    # Prepare a dictionary telling the session where to feed the minibatch.\n",
    "    # The key of the dictionary is the placeholder node of the graph to be fed,\n",
    "    # and the value is the numpy array to feed to it.\n",
    "    feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "    _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "    if (step % 5 == 0):\n",
    "      print(\"Minibatch loss at step %d: %f\" % (step, l))\n",
    "      print(\"Minibatch accuracy: %.1f%%\" % accuracy(predictions, batch_labels))\n",
    "      this_valid_acc = accuracy(valid_prediction.eval(), valid_labels)\n",
    "      print(\"Validation accuracy: %.1f%%\" % this_valid_acc)\n",
    "      if this_valid_acc < valid_accuracy and valid_accuracy > 83.4:\n",
    "        break\n",
    "      else:\n",
    "        valid_accuracy = this_valid_acc\n",
    "  assign_ops = [\n",
    "    weights1.assign(params['weights1']),\n",
    "    weights2.assign(params['weights2']),\n",
    "    weights3.assign(params['weights3']),\n",
    "    weights4.assign(params['weights4']),\n",
    "    biases1.assign(params['biases1']),\n",
    "    biases2.assign(params['biases2']),\n",
    "    biases3.assign(params['biases3']),\n",
    "    biases4.assign(params['biases4'])\n",
    "  ]\n",
    "  session.run(assign_ops)\n",
    "  print(\"Test accuracy: %.1f%%\" % accuracy(test_prediction.eval(), test_labels))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "default_view": {},
   "name": "3_regularization.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
